{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regreesion（线性回归）\n",
    "注意：python版本为3.6，\n",
    "安装TensorFlow的方法：pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      7\u001B[0m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mdisable_eager_execution()\n\u001B[1;32m----> 8\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGradientDescentOptimizer\u001B[49m(learning_rate)\u001B[38;5;241m.\u001B[39mminimize\n\u001B[0;32m      9\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mGradientDescentOptimizer(learning_rate)\u001B[38;5;241m.\u001B[39mminimize\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"dark\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize\n",
    "# TensorFlow2.0及以上版本没有GradientDescentOptimizer这个属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex1data1.txt', names=['population', 'profit'])#读取数据并赋予列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   population   profit\n",
       "0      6.1101  17.5920\n",
       "1      5.5277   9.1302\n",
       "2      8.5186  13.6620\n",
       "3      7.0032  11.8540\n",
       "4      5.8598   6.8233"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()#看前五行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   population  97 non-null     float64\n",
      " 1   profit      97 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 看下原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xyt556\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, data. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xyt556\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\seaborn\\regression.py:581: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot('population', 'profit', df, size=6, fit_reg=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(df):#读取特征\n",
    "#     \"\"\"\n",
    "#     use concat to add intersect feature to avoid side effect\n",
    "#     not efficient for big dataset though\n",
    "#     \"\"\"\n",
    "    ones = pd.DataFrame({'ones': np.ones(len(df))})#ones是m行1列的dataframe\n",
    "    data = pd.concat([ones, df], axis=1)  # 合并数据，根据列合并\n",
    "    return data.iloc[:, :-1].as_matrix()  # 这个操作返回 ndarray,不是矩阵\n",
    "\n",
    "\n",
    "def get_y(df):#读取标签\n",
    "#     '''assume the last column is the target'''\n",
    "    return np.array(df.iloc[:, -1])#df.iloc[:, -1]是指df的最后一列\n",
    "\n",
    "\n",
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())#特征缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多变量的假设 h 表示为：\\\\[{{h}_{\\theta }}\\left( x \\right)={{\\theta }_{0}}+{{\\theta }_{1}}{{x}_{1}}+{{\\theta }_{2}}{{x}_{2}}+...+{{\\theta }_{n}}{{x}_{n}}\\\\] \n",
    "这个公式中有n+1个参数和n个变量，为了使得公式能够简化一些，引入${{x}_{0}}=1$，则公式转化为：  \n",
    "此时模型中的参数是一个n+1维的向量，任何一个训练实例也都是n+1维的向量，特征矩阵X的维度是 m*(n+1)。 因此公式可以简化为：${{h}_{\\theta }}\\left( x \\right)={{\\theta }^{T}}X$，其中上标T代表矩阵转置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlinear_regression\u001B[39m(X_data, y_data, alpha, epoch, optimizer\u001B[38;5;241m=\u001B[39m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGradientDescentOptimizer\u001B[49m):\u001B[38;5;66;03m# 这个函数是旧金山的一个大神Lucas Shen写的\u001B[39;00m\n\u001B[0;32m      2\u001B[0m       \u001B[38;5;66;03m# placeholder for graph input\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     X \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mplaceholder(tf\u001B[38;5;241m.\u001B[39mfloat32, shape\u001B[38;5;241m=\u001B[39mX_data\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      4\u001B[0m     y \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mplaceholder(tf\u001B[38;5;241m.\u001B[39mfloat32, shape\u001B[38;5;241m=\u001B[39my_data\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "def linear_regression(X_data, y_data, alpha, epoch, optimizer=tf.train.GradientDescentOptimizer):# 这个函数是旧金山的一个大神Lucas Shen写的\n",
    "      # placeholder for graph input\n",
    "    X = tf.placeholder(tf.float32, shape=X_data.shape)\n",
    "    y = tf.placeholder(tf.float32, shape=y_data.shape)\n",
    "\n",
    "    # construct the graph\n",
    "    with tf.variable_scope('linear-regression'):\n",
    "        W = tf.get_variable(\"weights\",\n",
    "                            (X_data.shape[1], 1),\n",
    "                            initializer=tf.constant_initializer())  # n*1\n",
    "\n",
    "        y_pred = tf.matmul(X, W)  # m*n @ n*1 -> m*1\n",
    "\n",
    "        loss = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)  # (m*1).T @ m*1 = 1*1\n",
    "\n",
    "    opt = optimizer(learning_rate=alpha)\n",
    "    opt_operation = opt.minimize(loss)\n",
    "\n",
    "    # run the session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        loss_data = []\n",
    "\n",
    "        for i in range(epoch):\n",
    "            _, loss_val, W_val = sess.run([opt_operation, loss, W], feed_dict={X: X_data, y: y_data})\n",
    "            loss_data.append(loss_val[0, 0])  # because every loss_val is 1*1 ndarray\n",
    "\n",
    "            if len(loss_data) > 1 and np.abs(loss_data[-1] - loss_data[-2]) < 10 ** -9:  # early break when it's converged\n",
    "                # print('Converged at epoch {}'.format(i))\n",
    "                break\n",
    "\n",
    "    # clear the graph\n",
    "    tf.reset_default_graph()\n",
    "    return {'loss': loss_data, 'parameters': W_val}  # just want to return in row vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   population   profit\n",
       "0      6.1101  17.5920\n",
       "1      5.5277   9.1302\n",
       "2      8.5186  13.6620\n",
       "3      7.0032  11.8540\n",
       "4      5.8598   6.8233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ex1data1.txt', names=['population', 'profit'])#读取数据，并赋予列名\n",
    "\n",
    "data.head()#看下数据前5行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算代价函数\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{2m}\\sum\\limits_{i=1}^{m}{{{\\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}} \\right)}^{2}}}$$\n",
    "其中：\\\\[{{h}_{\\theta }}\\left( x \\right)={{\\theta }^{T}}X={{\\theta }_{0}}{{x}_{0}}+{{\\theta }_{1}}{{x}_{1}}+{{\\theta }_{2}}{{x}_{2}}+...+{{\\theta }_{n}}{{x}_{n}}\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mget_X\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;28mtype\u001B[39m(X))\n\u001B[0;32m      4\u001B[0m y \u001B[38;5;241m=\u001B[39m get_y(data)\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mget_X\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      6\u001B[0m ones \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mones\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mlen\u001B[39m(df))})\u001B[38;5;66;03m#ones是m行1列的dataframe\u001B[39;00m\n\u001B[0;32m      7\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([ones, df], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# 合并数据，根据列合并\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_matrix\u001B[49m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5569\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5570\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5571\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5572\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5573\u001B[0m ):\n\u001B[0;32m   5574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape, type(X))\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape, type(y))\n",
    "#看下数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(X.shape[1])#X.shape[1]=2,代表特征数n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_cost(theta, X, y):\n",
    "#     \"\"\"\n",
    "#     X: R(m*n), m 样本数, n 特征数\n",
    "#     y: R(m)\n",
    "#     theta : R(n), 线性回归的参数\n",
    "#     \"\"\"\n",
    "    m = X.shape[0]#m为样本数\n",
    "\n",
    "    inner = X @ theta - y  # R(m*1)，X @ theta等价于X.dot(theta)\n",
    "\n",
    "    # 1*m @ m*1 = 1*1 in matrix multiplication\n",
    "    # but you know numpy didn't do transpose in 1d array, so here is just a\n",
    "    # vector inner product to itselves\n",
    "    square_sum = inner.T @ inner\n",
    "    cost = square_sum / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cost(theta, X, y)#返回theta的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch gradient decent（批量梯度下降）\n",
    "$${{\\theta }_{j}}:={{\\theta }_{j}}-\\alpha \\frac{\\partial }{\\partial {{\\theta }_{j}}}J\\left( \\theta  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    inner = X.T @ (X @ theta - y)  # (m,n).T @ (m, 1) -> (n, 1)，X @ theta等价于X.dot(theta)\n",
    "\n",
    "    return inner / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_decent(theta, X, y, epoch, alpha=0.01):\n",
    "#   拟合线性回归，返回参数和代价\n",
    "#     epoch: 批处理的轮数\n",
    "#     \"\"\"\n",
    "    cost_data = [lr_cost(theta, X, y)]\n",
    "    _theta = theta.copy()  # 拷贝一份，不和原来的theta混淆\n",
    "\n",
    "    for _ in range(epoch):\n",
    "        _theta = _theta - alpha * gradient(_theta, X, y)\n",
    "        cost_data.append(lr_cost(_theta, X, y))\n",
    "\n",
    "    return _theta, cost_data\n",
    "#批量梯度下降函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 500\n",
    "final_theta, cost_data = batch_gradient_decent(theta, X, y, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta\n",
    "#最终的theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_data\n",
    "# 看下代价数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算最终的代价\n",
    "lr_cost(final_theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize cost data（代价数据可视化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.tsplot(cost_data, time=np.arange(epoch+1))\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('cost')\n",
    "plt.show()\n",
    "#可以看到从第二轮代价数据变换很大，接下来平稳了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = final_theta[0] # intercept，Y轴上的截距\n",
    "m = final_theta[1] # slope，斜率\n",
    "\n",
    "plt.scatter(data.population, data.profit, label=\"Training data\")\n",
    "plt.plot(data.population, data.population*m + b, label=\"Prediction\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- 选修章节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('ex1data2.txt', names=['square', 'bedrooms', 'price'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 标准化数据\n",
    "最简单的方法是令：\n",
    "\n",
    " \n",
    "\n",
    "其中  是平均值，sn 是标准差。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize_feature(raw_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. multi-var batch gradient decent（多变量批量梯度下降）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape, type(X))\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape, type(y))#看下数据的维度和类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01#学习率\n",
    "theta = np.zeros(X.shape[1])#X.shape[1]：特征数n\n",
    "epoch = 500#轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta, cost_data = batch_gradient_decent(theta, X, y, epoch, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.tsplot(time=np.arange(len(cost_data)), data = cost_data)\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('cost', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. learning rate（学习率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.logspace(-1, -5, num=4)\n",
    "candidate = np.sort(np.concatenate((base, base*3)))\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=50\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "for alpha in candidate:\n",
    "    _, cost_data = batch_gradient_decent(theta, X, y, epoch, alpha=alpha)\n",
    "    ax.plot(np.arange(epoch+1), cost_data, label=alpha)\n",
    "\n",
    "ax.set_xlabel('epoch', fontsize=18)\n",
    "ax.set_ylabel('cost', fontsize=18)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('learning rate', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. normal equation（正规方程）\n",
    "正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\\frac{\\partial }{\\partial {{\\theta }_{j}}}J\\left( {{\\theta }_{j}} \\right)=0$ 。\n",
    " 假设我们的训练集特征矩阵为 X（包含了${{x}_{0}}=1$）并且我们的训练集结果为向量 y，则利用正规方程解出向量 $\\theta ={{\\left( {{X}^{T}}X \\right)}^{-1}}{{X}^{T}}y$ 。\n",
    "上标T代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={{X}^{T}}X$，则：${{\\left( {{X}^{T}}X \\right)}^{-1}}={{A}^{-1}}$\n",
    "\n",
    "梯度下降与正规方程的比较：\n",
    "\n",
    "梯度下降：需要选择学习率α，需要多次迭代，当特征数量n大时也能较好适用，适用于各种类型的模型\t\n",
    "\n",
    "正规方程：不需要选择学习率α，一次计算得出，需要计算${{\\left( {{X}^{T}}X \\right)}^{-1}}$，如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为O(n3)，通常来说当n小于10000 时还是可以接受的，只适用于线性模型，不适合逻辑回归模型等其他模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正规方程\n",
    "def normalEqn(X, y):\n",
    "    theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta2=normalEqn(X, y)#感觉和批量梯度下降的theta的值有点差距\n",
    "final_theta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the tensorflow graph over several optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = get_X(data)\n",
    "print(X_data.shape, type(X_data))\n",
    "\n",
    "y_data = get_y(data).reshape(len(X_data), 1)  # special treatment for tensorflow input data\n",
    "print(y_data.shape, type(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2000\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_dict={'GD': tf.train.GradientDescentOptimizer,\n",
    "                'Adagrad': tf.train.AdagradOptimizer,\n",
    "                'Adam': tf.train.AdamOptimizer,\n",
    "                'Ftrl': tf.train.FtrlOptimizer,\n",
    "                'RMS': tf.train.RMSPropOptimizer\n",
    "               }\n",
    "results = []\n",
    "for name in optimizer_dict:\n",
    "    res = linear_regression(X_data, y_data, alpha, epoch, optimizer=optimizer_dict[name])\n",
    "    res['name'] = name\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "for res in results: \n",
    "    loss_data = res['loss']\n",
    "    \n",
    "#     print('for optimizer {}'.format(res['name']))\n",
    "#     print('final parameters\\n', res['parameters'])\n",
    "#     print('final loss={}\\n'.format(loss_data[-1]))\n",
    "    ax.plot(np.arange(len(loss_data)), loss_data, label=res['name'])\n",
    "\n",
    "ax.set_xlabel('epoch', fontsize=18)\n",
    "ax.set_ylabel('cost', fontsize=18)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('different optimizer', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
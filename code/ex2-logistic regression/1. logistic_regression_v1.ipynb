{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. logistic_regression（逻辑回归）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 备注\n",
    "运行环境：python 3.6  \n",
    "现在我知道我应该考虑列向量，而Tensorflow对数据的形状非常挑剔。 但是在numpy中，正常的一维ndarray已经被表示为列向量。 如果我重新塑造$\\mathbb{R}^n$ 为 $\\mathbb{R}^{n\\times1}$，它不再是列向量了，而是是1列的矩阵,那使用scipy会有麻烦。\n",
    "*所以我们应该把TensorFlow的数据视为特殊情况。 我们继续使用numpy的惯例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import classification_report#这个包是评价报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex2data1.txt', names=['exam1', 'exam2', 'admitted'])\n",
    "data.head()#看前五行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"darkgrid\", palette=sns.color_palette(\"RdBu\", 2))\n",
    "\n",
    "sns.lmplot('exam1', 'exam2', hue='admitted', data=data, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 50}\n",
    "          )\n",
    "plt.show()#看下数据的样子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_X(df):#读取特征\n",
    "#     \"\"\"\n",
    "#     use concat to add intersect feature to avoid side effect\n",
    "#     not efficient for big dataset though\n",
    "#     \"\"\"\n",
    "    ones = pd.DataFrame({'ones': np.ones(len(df))})#ones是m行1列的dataframe\n",
    "    data = pd.concat([ones, df], axis=1)  # 合并数据，根据列合并\n",
    "    return data.iloc[:, :-1].as_matrix()  # 这个操作返回 ndarray,不是矩阵\n",
    "\n",
    "\n",
    "def get_y(df):#读取标签\n",
    "#     '''assume the last column is the target'''\n",
    "    return np.array(df.iloc[:, -1])#df.iloc[:, -1]是指df的最后一列\n",
    "\n",
    "\n",
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())#特征缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape)\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sigmoid 函数\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： \\\\[g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}\\\\] \n",
    "合起来，我们得到逻辑回归模型的假设函数： \n",
    "\t\\\\[{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\\\\] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(-10, 10, step=0.01),\n",
    "        sigmoid(np.arange(-10, 10, step=0.01)))\n",
    "ax.set_ylim((-0.1,1.1))\n",
    "ax.set_xlabel('z', fontsize=18)\n",
    "ax.set_ylabel('g(z)', fontsize=18)\n",
    "ax.set_title('sigmoid function', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cost function(代价函数)\n",
    "> * $max(\\ell(\\theta)) = min(-\\ell(\\theta))$  \n",
    "> * choose $-\\ell(\\theta)$ as the cost function\n",
    "\n",
    "$$\\begin{align}\n",
    "  & J\\left( \\theta  \\right)=-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)+\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]} \\\\ \n",
    " & =\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]} \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "theta = theta=np.zeros(3) # X(m*n) so theta is n*1\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    ''' cost fn is -l(theta) for you to minimize'''\n",
    "    return np.mean(-y * np.log(sigmoid(X @ theta)) - (1 - y) * np.log(1 - sigmoid(X @ theta)))\n",
    "\n",
    "# X @ theta与X.dot(theta)等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cost(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent(梯度下降)\n",
    "* 这是批量梯度下降（batch gradient descent）  \n",
    "* 转化为向量化计算： $\\frac{1}{m} X^T( Sigmoid(X\\theta) - y )$\n",
    "$$\\frac{\\partial J\\left( \\theta  \\right)}{\\partial {{\\theta }_{j}}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}})x_{_{j}}^{(i)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "#     '''just 1 batch gradient'''\n",
    "    return (1 / len(X)) * X.T @ (sigmoid(X @ theta) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 拟合参数\n",
    "> * 这里我使用 [`scipy.optimize.minimize`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) 去寻找参数  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "res = opt.minimize(fun=cost, x0=theta, args=(X, y), method='Newton-CG', jac=gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用训练集预测和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    prob = sigmoid(x @ theta)\n",
    "    return (prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_theta = res.x\n",
    "y_pred = predict(X, final_theta)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 寻找决策边界\n",
    "http://stats.stackexchange.com/questions/93569/why-is-logistic-regression-a-linear-classifier\n",
    "> $X \\times \\theta = 0$  (this is the line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(res.x) # this is final theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "coef = -(res.x / res.x[2])  # find the equation\n",
    "print(coef)\n",
    "\n",
    "x = np.arange(130, step=0.1)\n",
    "y = coef[0] + coef[1]*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data.describe()  # find the range of x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> you know the intercept would be around 125 for both x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"ticks\", font_scale=1.5)\n",
    "\n",
    "sns.lmplot('exam1', 'exam2', hue='admitted', data=data, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 25}\n",
    "          )\n",
    "\n",
    "plt.plot(x, y, 'grey')\n",
    "plt.xlim(0, 130)\n",
    "plt.ylim(0, 130)\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3- 正则化逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"ticks\", font_scale=1.5)\n",
    "\n",
    "sns.lmplot('test1', 'test2', hue='accepted', data=df, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 50}\n",
    "          )\n",
    "\n",
    "plt.title('Regularized Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature mapping（特征映射）\n",
    "\n",
    "polynomial expansion\n",
    "\n",
    "```\n",
    "for i in 0..i\n",
    "  for p in 0..i:\n",
    "    output x^(i-p) * y^p\n",
    "```\n",
    "<img style=\"float: left;\" src=\"../img/mapped_feature.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_mapping(x, y, power, as_ndarray=False):\n",
    "#     \"\"\"return mapped features as ndarray or dataframe\"\"\"\n",
    "    # data = {}\n",
    "    # # inclusive\n",
    "    # for i in np.arange(power + 1):\n",
    "    #     for p in np.arange(i + 1):\n",
    "    #         data[\"f{}{}\".format(i - p, p)] = np.power(x, i - p) * np.power(y, p)\n",
    "\n",
    "    data = {\"f{}{}\".format(i - p, p): np.power(x, i - p) * np.power(y, p)\n",
    "                for i in np.arange(power + 1)\n",
    "                for p in np.arange(i + 1)\n",
    "            }\n",
    "\n",
    "    if as_ndarray:\n",
    "        return pd.DataFrame(data).as_matrix()\n",
    "    else:\n",
    "        return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x1 = np.array(df.test1)\n",
    "x2 = np.array(df.test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = feature_mapping(x1, x2, power=6)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized cost（正则化代价函数）\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(data.shape[1])\n",
    "X = feature_mapping(x1, x2, power=6, as_ndarray=True)\n",
    "print(X.shape)\n",
    "\n",
    "y = get_y(df)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def regularized_cost(theta, X, y, l=1):\n",
    "#     '''you don't penalize theta_0'''\n",
    "    theta_j1_to_n = theta[1:]\n",
    "    regularized_term = (l / (2 * len(X))) * np.power(theta_j1_to_n, 2).sum()\n",
    "\n",
    "    return cost(theta, X, y) + regularized_term\n",
    "#正则化代价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "regularized_cost(theta, X, y, l=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the same as the not regularized cost because we init theta as zeros...\n",
    "因为我们设置theta为0，所以这个正则化代价函数与代价函数的值相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized gradient(正则化梯度)\n",
    "$$\\frac{\\partial J\\left( \\theta  \\right)}{\\partial {{\\theta }_{j}}}=\\left( \\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left( {{h}_{\\theta }}\\left( {{x}^{\\left( i \\right)}} \\right)-{{y}^{\\left( i \\right)}} \\right)} \\right)+\\frac{\\lambda }{m}{{\\theta }_{j}}\\text{ }\\text{             for  j}\\ge \\text{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def regularized_gradient(theta, X, y, l=1):\n",
    "#     '''still, leave theta_0 alone'''\n",
    "    theta_j1_to_n = theta[1:]\n",
    "    regularized_theta = (l / len(X)) * theta_j1_to_n\n",
    "\n",
    "    # by doing this, no offset is on theta_0\n",
    "    regularized_term = np.concatenate([np.array([0]), regularized_theta])\n",
    "\n",
    "    return gradient(theta, X, y) + regularized_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "regularized_gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拟合参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('init cost = {}'.format(regularized_cost(theta, X, y)))\n",
    "\n",
    "res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, y), method='Newton-CG', jac=regularized_gradient)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_theta = res.x\n",
    "y_pred = predict(X, final_theta)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用不同的 $\\lambda$ （这个是常数）\n",
    "# 画出决策边界\n",
    "* 我们找到所有满足 $X\\times \\theta = 0$ 的x\n",
    "* instead of solving polynomial equation, just create a coridate x,y grid that is dense enough, and find all those $X\\times \\theta$ that is close enough to 0, then plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def draw_boundary(power, l):\n",
    "#     \"\"\"\n",
    "#     power: polynomial power for mapped feature\n",
    "#     l: lambda constant\n",
    "#     \"\"\"\n",
    "    density = 1000\n",
    "    threshhold = 2 * 10**-3\n",
    "\n",
    "    final_theta = feature_mapped_logistic_regression(power, l)\n",
    "    x, y = find_decision_boundary(density, power, final_theta, threshhold)\n",
    "\n",
    "    df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "    sns.lmplot('test1', 'test2', hue='accepted', data=df, size=6, fit_reg=False, scatter_kws={\"s\": 100})\n",
    "\n",
    "    plt.scatter(x, y, c='R', s=10)\n",
    "    plt.title('Decision boundary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_mapped_logistic_regression(power, l):\n",
    "#     \"\"\"for drawing purpose only.. not a well generealize logistic regression\n",
    "#     power: int\n",
    "#         raise x1, x2 to polynomial power\n",
    "#     l: int\n",
    "#         lambda constant for regularization term\n",
    "#     \"\"\"\n",
    "    df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "    x1 = np.array(df.test1)\n",
    "    x2 = np.array(df.test2)\n",
    "    y = get_y(df)\n",
    "\n",
    "    X = feature_mapping(x1, x2, power, as_ndarray=True)\n",
    "    theta = np.zeros(X.shape[1])\n",
    "\n",
    "    res = opt.minimize(fun=regularized_cost,\n",
    "                       x0=theta,\n",
    "                       args=(X, y, l),\n",
    "                       method='TNC',\n",
    "                       jac=regularized_gradient)\n",
    "    final_theta = res.x\n",
    "\n",
    "    return final_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def find_decision_boundary(density, power, theta, threshhold):\n",
    "    t1 = np.linspace(-1, 1.5, density)\n",
    "    t2 = np.linspace(-1, 1.5, density)\n",
    "\n",
    "    cordinates = [(x, y) for x in t1 for y in t2]\n",
    "    x_cord, y_cord = zip(*cordinates)\n",
    "    mapped_cord = feature_mapping(x_cord, y_cord, power)  # this is a dataframe\n",
    "\n",
    "    inner_product = mapped_cord.as_matrix() @ theta\n",
    "\n",
    "    decision = mapped_cord[np.abs(inner_product) < threshhold]\n",
    "\n",
    "    return decision.f10, decision.f01\n",
    "#寻找决策边界函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=1)#lambda=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=0)  # no regularization, over fitting，#lambda=0,没有正则化，过拟合了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=100)  # underfitting，#lambda=100,欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
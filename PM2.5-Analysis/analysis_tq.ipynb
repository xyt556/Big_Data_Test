{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "徐州市逐年PM2.5含量数据分析 & 数据可视化 & 使用回归模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断本地是否已有数据，若无数据，则爬取徐州市历年PM2.5每日数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 22>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#判断本地是否已有数据，若无则运行爬虫\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtq_xuzhou2022.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m==\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 23\u001B[0m     \u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m本地已有数据！\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mget_data\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m url \u001B[38;5;129;01min\u001B[39;00m url_list:\n\u001B[0;32m     14\u001B[0m     url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://www.tianqihoubao.com\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39murl\n\u001B[1;32m---> 15\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;66;03m# , encoding='gbk'\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data)\n\u001B[0;32m     17\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\io\\html.py:1113\u001B[0m, in \u001B[0;36mread_html\u001B[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001B[0m\n\u001B[0;32m   1109\u001B[0m validate_header_arg(header)\n\u001B[0;32m   1111\u001B[0m io \u001B[38;5;241m=\u001B[39m stringify_path(io)\n\u001B[1;32m-> 1113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflavor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflavor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecimal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecimal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_default_na\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_na\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisplayed_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisplayed_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\io\\html.py:939\u001B[0m, in \u001B[0;36m_parse\u001B[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001B[0m\n\u001B[0;32m    937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    938\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m retained \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# for mypy\u001B[39;00m\n\u001B[1;32m--> 939\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retained\n\u001B[0;32m    941\u001B[0m ret \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    942\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m table \u001B[38;5;129;01min\u001B[39;00m tables:\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\io\\html.py:919\u001B[0m, in \u001B[0;36m_parse\u001B[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001B[0m\n\u001B[0;32m    916\u001B[0m p \u001B[38;5;241m=\u001B[39m parser(io, compiled_match, attrs, encoding, displayed_only)\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 919\u001B[0m     tables \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_tables\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m caught:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001B[39;00m\n\u001B[0;32m    922\u001B[0m     \u001B[38;5;66;03m# and try to rewind it before trying the next parser\u001B[39;00m\n\u001B[0;32m    923\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(io, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseekable\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m io\u001B[38;5;241m.\u001B[39mseekable():\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\io\\html.py:239\u001B[0m, in \u001B[0;36m_HtmlFrameParser.parse_tables\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_tables\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;124;03m    Parse and return all tables from the DOM.\u001B[39;00m\n\u001B[0;32m    234\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 239\u001B[0m     tables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_tables\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_doc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_thead_tbody_tfoot(table) \u001B[38;5;28;01mfor\u001B[39;00m table \u001B[38;5;129;01min\u001B[39;00m tables)\n",
      "File \u001B[1;32m~\\PycharmProjects\\big_data\\envi\\lib\\site-packages\\pandas\\io\\html.py:569\u001B[0m, in \u001B[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001B[1;34m(self, doc, match, attrs)\u001B[0m\n\u001B[0;32m    566\u001B[0m tables \u001B[38;5;241m=\u001B[39m doc\u001B[38;5;241m.\u001B[39mfind_all(element_name, attrs\u001B[38;5;241m=\u001B[39mattrs)\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tables:\n\u001B[1;32m--> 569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo tables found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    571\u001B[0m result \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    572\u001B[0m unique_tables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mValueError\u001B[0m: No tables found"
     ]
    }
   ],
   "source": [
    "import time,requests,re\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "def get_data():\n",
    "    url='http://www.tianqihoubao.com/lishi/xuzhou.html'\n",
    "    headers={'user-agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362\", }\n",
    "    response=requests.get(url, headers=headers)\n",
    "    html=response.text\n",
    "    response=etree.HTML(html)\n",
    "    url_list=response.xpath('//div[@class=\"box p\"]//a/@href')\n",
    "    for url in url_list:\n",
    "        url='http://www.tianqihoubao.com'+url\n",
    "        data=pd.read_html(url, header=0)[0] # , encoding='gbk'\n",
    "        print(data)\n",
    "        time.sleep(1)\n",
    "        data.to_csv(\"tq_xuzhou2022.csv\",mode='a', header=False)\n",
    "\n",
    "\n",
    "#判断本地是否已有数据，若无则运行爬虫\n",
    "if(os.path.exists(\"tq_xuzhou2022.csv\")==False):\n",
    "    get_data()\n",
    "else:\n",
    "    print(\"本地已有数据！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "filename = \"pm2.5_xuzhou.csv\"\n",
    "df=pd.read_csv(filename,names=['date','quality','AQI','ranking','PM2.5(μg/m3)','Pm10(μg/m3)','So2(μg/m3)','No2(μg/m3)','Co(mg/m3)','O3(μg/m3)'])\n",
    "df   \n",
    "\n",
    "#经验证爬取的文件无缺失和异常数据，故无需进行处理\n",
    "\n",
    "#获取的数据如下，数据有 date、qulaity、AQI、ranking、PM2.5 等字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#把时间字符串转为索引\n",
    "df['time_index']=pd.to_datetime(df['date']) \n",
    "df.set_index('time_index',inplace=True)\n",
    "df\n",
    "#可以看到时间索引在最左边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#将每日数据绘制成折线图\n",
    "plot=df['PM2.5(μg/m3)'].plot(figsize=(25,10),title=\"Xuzhou Daily PM2.5 (ug/m3) 2013/11 - 2020/05 \",color='darkorange', grid=True,fontsize=15)\n",
    "fig=plot.get_figure()\n",
    "fig.savefig(\"Xuzhou Daily PM2.5.png\")\n",
    "\n",
    "#数据太密集，无法看出数据的趋势，数据需要处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#降低数据采样频率\n",
    "df1=df.resample('M').mean()     #月份采样，取月平均值\n",
    " \n",
    "#绘制折线图：\n",
    "plt.figure(figsize=(25,10))\n",
    "data=df1['PM2.5(μg/m3)']\n",
    "#print(data.index)\n",
    "#print(data.values)\n",
    " \n",
    "_x=data.index\n",
    "_y=data.values\n",
    "_x = [i.strftime(\"%Y/ %m\") for i in _x]\n",
    "plt.plot(range(len(_x)), _y,'darkorange')\n",
    "plt.xticks(range(len(_x)), _x, rotation=70)\n",
    "plt.grid(color='black', linestyle='-', linewidth=0.8,alpha=0.4)\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('PM2.5(ug/m3)')\n",
    "plt.title('Xuzhou Monthly Average PM2.5 (ug/m3) 2013/11 - 2020/05 ')\n",
    "plt.savefig('Xuzhou Monthly Average PM2.5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#为了更清楚地看到数据趋势，再次降低数据采样频率\n",
    "df2=df.resample('Y').mean()   #年份采样，取年平均\n",
    " \n",
    "#绘制折线图：\n",
    "plt.figure(figsize=(25,10))\n",
    "data=df2['PM2.5(μg/m3)']\n",
    "#print(data.index)\n",
    "#print(data.values)\n",
    " \n",
    "_x=data.index\n",
    "_y=data.values\n",
    "_x = [i.strftime(\"%Y \") for i in _x]\n",
    "plt.plot(range(len(_x)), _y,'darkorange')\n",
    "plt.xticks(range(len(_x)), _x, rotation=70)\n",
    "plt.grid(color='black', linestyle='-', linewidth=0.8,alpha=0.4)\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('PM2.5(ug/m3)')\n",
    "plt.title('Xuzhou Yearly Average PM2.5 (ug/m3) 2013 - 2020 ')\n",
    "plt.savefig('Xuzhou Yearly Average PM2.5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PM2.5含量逐年下降的主要原因可能是：\n",
    "\n",
    "（1）政府出台相关政策，控制源头，加强工业粉尘治理\n",
    "\n",
    "（2）城市汽车限行，控制尾气排放\n",
    "\n",
    "（3）改善了能源消耗结构\n",
    "\n",
    "（4）人们对PM2.5的危害有更加深刻的认识和了解\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#为了接下来的数据处理和可视化，需要增加一些字段\n",
    "\n",
    "df['dayofyear'] = df.index.dayofyear   #添加一年中第几天字段\n",
    "df['dayofweek'] = df.index.dayofweek   #添加星期几字段（0-6）\n",
    "df['season'] = df.index.quarter        #添加季节字段（1-4）\n",
    "df['year']=df.index.year               #增加年字段\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.nsmallest(10,'PM2.5(μg/m3)')  #查看数据中某日PM2.5含量最低的前10名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.nlargest(10,'PM2.5(μg/m3)')     #查看数据中某日PM2.5含量最高的前10名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们要用年份来分组，查看每年PM2.5含量数据的情况并画出相关数据图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "groupby_year=df['PM2.5(μg/m3)'].groupby(df['year'])  #按年划分数据\n",
    "groupby_year.describe()  \n",
    "\n",
    "#可以看到每年的PM2.5的 总和，平均值，最大最小值等等的数据都已自动算好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#绘制柱状图查看每年PM2.5最大、最小和平均含量\n",
    "import numpy as np\n",
    "year=['2013','2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "y1=groupby_year.min().tolist()    #最小值list\n",
    "\n",
    "meanlist=groupby_year.mean().tolist()\n",
    "y2=[round(i,2) for i in meanlist]    #平均值list只保留小数点后3位\n",
    "\n",
    "y3=groupby_year.max().tolist()     #最大值list\n",
    "\n",
    "x = np.arange(len(year))\n",
    "width=0.3\n",
    "\n",
    "plt.bar(x,y1,width=width,label='min',color='green')\n",
    "plt.bar(x+width,y2,width=width,label='mean',color='deepskyblue',tick_label=year)\n",
    "plt.bar(x+2*width,y3,width=width,label='max',color='darkorange')\n",
    "\n",
    "#在图中每个柱条显示数据大小\n",
    "for a,b in zip(x,y1):\n",
    "    plt.text(a,b+0.1,b,ha='center',va='bottom')\n",
    "for a,b in zip(x,y2):\n",
    "    plt.text(a+width,b+0.1,b,ha='center',va='bottom')\n",
    "for a,b in zip(x,y3):\n",
    "    plt.text(a+2*width,b+0.1,b,ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize']=(25.0,10.0)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('PM2.5(ug/m3)')\n",
    "plt.xticks()\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Yearly Compare\")\n",
    "plt.savefig('Yearly compare.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着绘制饼图查看每年空气污染程度占比，（这里排除了2013年和2020年的数据，因为数据不完整）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#按年划分数据，再按空气质量划分数据\n",
    "df2014=df[df.year==2014]\n",
    "groupby_quality2014=df2014['AQI'].groupby(df2014['quality'])  \n",
    "groupby_quality2014.describe()   #2014年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2015=df[df.year==2015]\n",
    "groupby_quality2015=df2015['AQI'].groupby(df2015['quality']) \n",
    "groupby_quality2015.describe()   #2015年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2016=df[df.year==2016]\n",
    "groupby_quality2016=df2016['AQI'].groupby(df2016['quality'])  \n",
    "groupby_quality2016.describe()   #2016年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2017=df[df.year==2017]\n",
    "groupby_quality2017=df2017['AQI'].groupby(df2017['quality'])  \n",
    "groupby_quality2017.describe()   #2017年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2018=df[df.year==2018]\n",
    "groupby_quality2018=df2018['AQI'].groupby(df2018['quality'])  \n",
    "groupby_quality2018.describe()   #2018年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2019=df[df.year==2019]\n",
    "groupby_quality2019=df2019['AQI'].groupby(df2019['quality'])  \n",
    "groupby_quality2019.describe()    #2019年数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#绘制饼图\n",
    "# labels=['中度污染','优','良','轻度污染']\n",
    "labels=['严重污染','中度污染','优','良','轻度污染','重度污染']\n",
    "colors=['red','pink','green','skyblue','orange','black']\n",
    "labels1=['优','良','轻度污染']\n",
    "count2014=groupby_quality2014.count().tolist()\n",
    "count2015=groupby_quality2015.count().tolist()\n",
    "count2016=groupby_quality2016.count().tolist()\n",
    "count2017=groupby_quality2017.count().tolist()\n",
    "count2018=groupby_quality2018.count().tolist()\n",
    "count2019=groupby_quality2019.count().tolist()\n",
    "\n",
    "ex=[0.01,0.01,0.01,0.01,0.01,0.01]\n",
    "ex1=[0.01,0.01,0.01]\n",
    "\n",
    "pic=plt.figure(figsize=(25,15))\n",
    "\n",
    "a1=pic.add_subplot(2,3,1)\n",
    "plt.rcParams['font.sans-serif']='SimHei'\n",
    "plt.pie(count2014,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2014全年空气质量饼图')\n",
    "\n",
    "a1=pic.add_subplot(2,3,2)\n",
    "plt.pie(count2015,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2015全年空气质量饼图')\n",
    "\n",
    "a1=pic.add_subplot(2,3,3)\n",
    "plt.pie(count2016,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2016全年空气质量饼图')\n",
    "\n",
    "a1=pic.add_subplot(2,3,4)\n",
    "plt.pie(count2017,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2017全年空气质量饼图')\n",
    "\n",
    "a1=pic.add_subplot(2,3,5)\n",
    "plt.pie(count2018,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2018全年空气质量饼图')\n",
    "\n",
    "a1=pic.add_subplot(2,3,6)\n",
    "plt.pie(count2019,explode=ex,labels=labels,colors=colors,autopct='%1.1f%%')\n",
    "plt.title('徐州2019全年空气质量饼图')\n",
    "\n",
    "plt.savefig('pie.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#画出热力图，查看字段间的相关性\n",
    "#相关系数的绝对值在【0.5,1】之间是强相关  【0.2,0.5】之间是有一定相关  小于0.1或0.05是无相关\n",
    "PM_corr = df.corr()\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "sns.heatmap(PM_corr,annot=True)\n",
    "plt.savefig('heatmap.png')\n",
    "\n",
    "#注重分析PM2.5字段和其他字段的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据热力图可以得出结论：\n",
    "\n",
    "（1）PM2.5含量与O3含量有一定相关性，与CO，NO2，SO2的含量强相关。主要原因是这些气体都是污染气体。\n",
    "\n",
    "（2）PM2.5的含量与AQI指数强相关，即PM2.5的含量影响着AQI指数。\n",
    "\n",
    "（3）PM2.5与年之间是负相关，含量逐年减少\n",
    "\n",
    "（4）PM2.5与季节的相关性不大\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着使用 普通线性回归模型、岭回归模型和Lasso回归模型  3种不同的回归模型来预测数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "split_percent=0.1\n",
    "data_train=df.iloc[int(len(df)*split_percent):]  #前80%的数据划为训练集 \n",
    "data_test=df.iloc[:int(len(df)*split_percent)]   #剩余20%划为测试集   \n",
    "\n",
    "test_time=data_test['date']\n",
    "#type(test_time)\n",
    "data_test    #测试集数据范围是2019年1月17日 —— 2020年5月1日\n",
    "#data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#剔除字符串字段\n",
    "data_train=data_train.drop(['date','quality'], axis = 1)\n",
    "data_test=data_test.drop(['date','quality'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_train=data_train['PM2.5(μg/m3)'].values\n",
    "x_train=data_train.drop('PM2.5(μg/m3)', axis = 1).values\n",
    "\n",
    "y_true=data_test['PM2.5(μg/m3)'].values\n",
    "x_test=data_test.drop('PM2.5(μg/m3)', axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_true   #PM2.5含量真实值（2019-01-17 ——  2020-05-01）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用普通的线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "np.around(y_pred,decimals=1)  #控制输出小数点后一位\n",
    "#PM2.5含量 普通线性回归模型 预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着使用岭回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#先选取最佳alpha参数\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridgecv = RidgeCV(alphas=[0.01, 0.1, 0.5, 1, 3, 5, 7, 10, 20, 100])\n",
    "ridgecv.fit(x_train, y_train)\n",
    "ridgecv.alpha_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "reg=Ridge(alpha = 0.1)  #使用上面的alpha参数\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred_reg=reg.predict(x_test)\n",
    "\n",
    "np.around(y_pred_reg,decimals=1)  #控制输出小数点后一位\n",
    "#PM2.5含量 岭回归模型 预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后使用Lasso回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso(alpha = 0.01)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred_lasso=lasso.predict(x_test)\n",
    "np.around(y_pred_lasso,decimals=1)  #控制输出小数点后一位\n",
    "#PM2.5含量 Lasso回归模型 预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三种回归模型的评价\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,mean_squared_error,median_absolute_error,r2_score\n",
    "\n",
    "print('线性回归模型评价')\n",
    "print('数据线性回归模型的平均绝对误差为',mean_absolute_error(y_true,y_pred).round(8))\n",
    "print('数据线性回归模型的均方误差为',mean_squared_error(y_true,y_pred).round(8))\n",
    "print('数据线性回归模型的中值绝对误差为',median_absolute_error(y_true,y_pred).round(8))\n",
    "print('数据线性回归模型的可解释方差值为',explained_variance_score(y_true,y_pred).round(8))\n",
    "print('数据线性回归模型的R方值为',r2_score(y_true,y_pred).round(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('岭回归模型评价')\n",
    "print('数据岭回归模型的平均绝对误差为',mean_absolute_error(y_true,y_pred_reg).round(8))\n",
    "print('数据岭回归模型的均方误差为',mean_squared_error(y_true,y_pred_reg).round(8))\n",
    "print('数据岭回归模型的中值绝对误差为',median_absolute_error(y_true,y_pred_reg).round(8))\n",
    "print('数据岭回归模型的可解释方差值为',explained_variance_score(y_true,y_pred_reg).round(8))\n",
    "print('数据岭回归模型的R方值为',r2_score(y_true,y_pred_reg).round(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Lasso回归模型评价')\n",
    "print('数据Lasso回归模型的平均绝对误差为',mean_absolute_error(y_true,y_pred_lasso).round(8))\n",
    "print('数据Lasso回归模型的均方误差为',mean_squared_error(y_true,y_pred_lasso).round(8))\n",
    "print('数据Lasso回归模型的中值绝对误差为',median_absolute_error(y_true,y_pred_lasso).round(8))\n",
    "print('数据Lasso回归模型的可解释方差值为',explained_variance_score(y_true,y_pred_lasso).round(8))\n",
    "print('数据Lasso回归模型的R方值为',r2_score(y_true,y_pred_lasso).round(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制折线图，看不同模型间的拟合程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先将预测的结果转为 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#真实值\n",
    "time=test_time.values\n",
    "df_true=pd.DataFrame({'date':time,'PM2.5(μg/m3)':y_true})\n",
    "df_true['time_index'] = pd.to_datetime(df_true['date']) #把时间字符串转为索引\n",
    "df_true.set_index('time_index',inplace=True)\n",
    "#df_true\n",
    "\n",
    "#普通线性回归模型预测的结果\n",
    "df_mod1=pd.DataFrame({'date':time,'PM2.5(μg/m3)':y_pred})\n",
    "df_mod1['time_index'] = pd.to_datetime(df_mod1['date']) #把时间字符串转为索引\n",
    "df_mod1.set_index('time_index',inplace=True)\n",
    "#df_mod1\n",
    "\n",
    "#岭回归模型预测的结果\n",
    "df_mod2=pd.DataFrame({'date':time,'PM2.5(μg/m3)':y_pred_reg})\n",
    "df_mod2['time_index'] = pd.to_datetime(df_mod2['date']) #把时间字符串转为索引\n",
    "df_mod2.set_index('time_index',inplace=True)\n",
    "#df_mod2\n",
    "\n",
    "#Lasso回归模型预测的结果\n",
    "df_mod3=pd.DataFrame({'date':time,'PM2.5(μg/m3)':y_pred_lasso})\n",
    "df_mod3['time_index'] = pd.to_datetime(df_mod3['date']) #把时间字符串转为索引\n",
    "df_mod3.set_index('time_index',inplace=True)\n",
    "#df_mod3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#绘制图像\n",
    "df_true['PM2.5(μg/m3)'].plot(figsize=(25,10),color='red', grid=True,fontsize=15,label='True')                       #真实数据\n",
    "df_mod1['PM2.5(μg/m3)'].plot(figsize=(25,10),color='darkorange', grid=True,fontsize=15,label='LinearRegression')     #普通线性回归模型预测数据\n",
    "df_mod2['PM2.5(μg/m3)'].plot(figsize=(25,10),color='green', grid=True,fontsize=15,label='Ridge')                    #岭回归模型预测数据\n",
    "df_mod3['PM2.5(μg/m3)'].plot(figsize=(25,10),color='lightblue', grid=True,fontsize=15,label='Lasso')                 #Lasso回归模型预测数据\n",
    "plt.xticks()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Model Compare.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中也可以看到，三种模型预测的结果差别不大"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}